{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "def parse_xlsx(filename, sheetname):\n",
    "    wb = load_workbook(filename=filename, read_only=True)\n",
    "    ws = wb[sheetname]\n",
    "\n",
    "    sheet_rows = list()\n",
    "    for num, row in enumerate(ws.rows):\n",
    "        if num == 0:\n",
    "            headers = [i.value for i in row]\n",
    "        else:\n",
    "            row_cells = [i.value for i in row]\n",
    "            row_dict = dict(zip(headers, row_cells))\n",
    "            sheet_rows.append(row_dict)\n",
    "    return sheet_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrowing_requests = parse_xlsx('Feb13MikeSource/ILL Borrowing Requests (Loan) - 1-1-2016 - 12-31-2018 - Patron Recommendations.xlsx', 'Sheet')\n",
    "# illrecpur = parse_xlsx('Feb13MikeSource/ILLRECPUR FY16 thru FY18 with usage thru 12-20-2018.xlsx', 'output_gjzj3985083270205064418') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "borrowing_requests = [i for i in borrowing_requests\n",
    "                     if set(i.values()) != {None,}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find exact complete matching rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in borrowing_requests:\n",
    "    if isinstance(i['Creation Date'], str):\n",
    "        continue\n",
    "    try:\n",
    "        date = i['Creation Date']\n",
    "        formatted_date = f\"{date.month}/{date.day}/{date.year}\"\n",
    "        i['Creation Date'] = formatted_date\n",
    "    except:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_doubles = list()\n",
    "already_in_exact_doubles = list()\n",
    "others = list()\n",
    "\n",
    "temp_found_so_far = list()\n",
    "\n",
    "for row in borrowing_requests:\n",
    "    if row in temp_found_so_far:\n",
    "        if row not in exact_doubles:\n",
    "            exact_doubles.append(row)\n",
    "        else:\n",
    "            already_in_exact_doubles.append(row)\n",
    "    else:\n",
    "        temp_found_so_far.append(row)\n",
    "        \n",
    "for row in temp_found_so_far:\n",
    "    if row in exact_doubles:\n",
    "        already_in_exact_doubles.append(row)\n",
    "    else:\n",
    "        if row not in others:\n",
    "            others.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(borrowing_requests), len(exact_doubles), len(already_in_exact_doubles), len(others), len(temp_found_so_far))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in exact_doubles:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find those that match Author/Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_done_already = set()\n",
    "temp_done_already_full_record = list()\n",
    "author_title_matches = list()\n",
    "not_author_title_match = list()\n",
    "\n",
    "already_in_author_title_matches = list()\n",
    "others2 = list()\n",
    "\n",
    "for source_item in others:\n",
    "    source_author, source_title = source_item['Loan Author'], source_item['Loan Title']\n",
    "    if not temp_done_already:\n",
    "        temp_done_already.add((source_author, source_title))\n",
    "        temp_done_already_full_record.append(source_item)\n",
    "        continue\n",
    "    if (source_author, source_title) in temp_done_already:\n",
    "        author_title_matches.append(source_item)\n",
    "    else:\n",
    "        temp_done_already.add((source_author, source_title))\n",
    "        temp_done_already_full_record.append(source_item)\n",
    "        \n",
    "for row in temp_done_already_full_record:\n",
    "    for match_item in author_title_matches:\n",
    "        if (row['Loan Author'], row['Loan Title']) == (match_item['Loan Author'], match_item['Loan Title']):\n",
    "            already_in_author_title_matches.append(row)\n",
    "            break\n",
    "    else:\n",
    "        for others2_item in others2:\n",
    "            if (row['Loan Author'], row['Loan Title']) == (others2_item['Loan Author'], others2_item['Loan Title']):\n",
    "                break\n",
    "        else:\n",
    "            others2.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(others), len(author_title_matches), len(already_in_author_title_matches), len(others2), len(temp_done_already)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in others2:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the fuzzy matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "def make_matches(parsed_sheet1, parsed_sheet2):\n",
    "    possible_matches = list()\n",
    "    for num, sheet1_row in enumerate(parsed_sheet1):\n",
    "        sheet1_row_title = sheet1_row['title']\n",
    "        for sheet2_row in parsed_sheet2:\n",
    "            if sheet2_row == sheet1_row:\n",
    "                continue\n",
    "            sheet2_row_title = sheet2_row['Loan Title']\n",
    "            title_ratio = fuzz.token_sort_ratio(sheet1_row_title, sheet2_row_title)\n",
    "            title_ratios.append(title_ratio)\n",
    "            if title_ratio > 75:\n",
    "                possible_matches.append((title_ratio, sheet1_row, sheet2_row))\n",
    "    return possible_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_matches = list()\n",
    "temp_these_done = set()\n",
    "temp_these_done_full_record = list()\n",
    "not_fuzzy_matches = list()\n",
    "\n",
    "already_in_fuzzy_matches = list()\n",
    "others3 = list()\n",
    "\n",
    "title_ratios = list()\n",
    "\n",
    "fuzzy_matches = make_matches(others2, others2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio, a, b in fuzzy_matches:\n",
    "    print(ratio)\n",
    "    print(a['Loan Title'])\n",
    "    print(b['Loan Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(len([n for n in title_ratios if i * 10 < n < 10 + i * 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_dict_to_csv(output_filename, a_list_of_dicts):\n",
    "    with open(output_filename, 'w', newline='') as csvfile:\n",
    "        fieldnames = a_list_of_dicts[0].keys()\n",
    "        spamwriter = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        spamwriter.writeheader()\n",
    "        for row in a_list_of_dicts:\n",
    "            spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_csv('Feb13MikeSource/FullMatches.csv', exact_doubles)\n",
    "write_dict_to_csv('Feb13MikeSource/AuthorTitleMatches.csv', author_title_matches)\n",
    "write_dict_to_csv('Feb13MikeSource/Other2.csv', others2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_fuzzy_matches = list()\n",
    "for a, b, c in fuzzy_matches:\n",
    "    flattened_fuzzy_matches.extend([b, c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export fuzzy matches to spreadsheet\n",
    "\n",
    "  manually delete the non-matching pair rows\n",
    "  \n",
    "  convert the csv back into a list of dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is meant to be user-revised -- so do generate it twice.\n",
    "# write_dict_to_csv('Feb13MikeSource/FuzzyMatches.csv', flattened_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "hand_filtered_fuzzy_matches = list()\n",
    "\n",
    "with open('Feb13MikeSource/FuzzyMatches.csv', 'r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',', quotechar='\"')\n",
    "    for num, row in enumerate(reader):\n",
    "        if num == 0:\n",
    "            headers = row\n",
    "            continue\n",
    "        row_dict = dict(zip(headers, row))\n",
    "#         if row_dict not in hand_filtered_fuzzy_matches:\n",
    "        hand_filtered_fuzzy_matches.append(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hand_filtered_fuzzy_matches[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_fuzzy_matches = list()\n",
    "\n",
    "def merge_fuzzy_copies(a, b):\n",
    "    a_trans, b_trans = int(a['Transaction Number']), int(b['Transaction Number'])\n",
    "    if not merged_fuzzy_matches:\n",
    "        merged_fuzzy_matches.append([a_trans, b_trans])\n",
    "        return\n",
    "    if 5303239 in (a_trans, b_trans):\n",
    "        print(a_trans, b_trans)\n",
    "    for i in merged_fuzzy_matches:\n",
    "        if a_trans in i and b_trans in i:\n",
    "            break\n",
    "        elif a_trans in i:\n",
    "            i.append(b_trans)\n",
    "            break\n",
    "        elif b_trans in i:         \n",
    "            i.append(a_trans)\n",
    "            break\n",
    "    else:\n",
    "        merged_fuzzy_matches.append([a_trans, b_trans])\n",
    "#     print(merged_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, i in enumerate(hand_filtered_fuzzy_matches):\n",
    "    if num % 2 != 0:\n",
    "        a = hand_filtered_fuzzy_matches[num-1]\n",
    "        b = hand_filtered_fuzzy_matches[num]\n",
    "        merge_fuzzy_copies(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(merged_fuzzy_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in merged_fuzzy_matches:\n",
    "    if len(i) > 2:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find matches in ILLRECPUR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illrecpur = parse_xlsx('Feb13MikeSource/ILLRECPUR FY16 thru FY18 with usage thru 12-20-2018.xlsx', 'output_gjzj3985083270205064418') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flexkeys = set()\n",
    "\n",
    "duplicate_items = list()\n",
    "\n",
    "for row in illrecpur:\n",
    "    flexkey = row['flexkey']\n",
    "    if flexkey in all_flexkeys:\n",
    "        if row not in duplicate_items:\n",
    "            duplicate_items.append(row)\n",
    "    all_flexkeys.add(flexkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicate_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_flexkeys = set(i['flexkey'] for i in duplicate_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(duplicate_flexkeys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_csv('Feb13MikeSource/duplicate_illrecpur.csv', duplicate_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_dict = dict()\n",
    "\n",
    "for flexkey in duplicate_flexkeys:\n",
    "    counts = 0\n",
    "    for row in illrecpur:\n",
    "        if row['flexkey'] == flexkey:\n",
    "            counts += 1\n",
    "    counts_dict[flexkey] = counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduped_illrecpur = list()\n",
    "dupes_done = set()\n",
    "\n",
    "for row in illrecpur:\n",
    "    row_flexkey = row['flexkey']\n",
    "    if row_flexkey not in duplicate_flexkeys:\n",
    "        row['duplicate counts'] = 1\n",
    "        deduped_illrecpur.append(row)\n",
    "    else:\n",
    "        if row_flexkey not in dupes_done:\n",
    "            row['duplicate counts'] = counts_dict[row_flexkey]\n",
    "            deduped_illrecpur.append(row)\n",
    "            dupes_done.add(row_flexkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(deduped_illrecpur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(illrecpur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_csv('Feb13MikeSource/CountsDuplicatesILLRECPUR.csv', deduped_illrecpur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_illrecpur = [i for i in deduped_illrecpur if int(i['duplicate counts']) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reduced_illrecpur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_csv('Feb13MikeSource/ReducedDuplicatesILLRECPUR.csv', reduced_illrecpur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratios = list()\n",
    "\n",
    "def make_matches(parsed_sheet1, parsed_sheet2):\n",
    "    possible_matches = list()\n",
    "    for num, sheet1_row in enumerate(parsed_sheet1):\n",
    "        sheet1_row_title = sheet1_row['title']\n",
    "        for sheet2_row in parsed_sheet2:\n",
    "            if sheet2_row == sheet1_row:\n",
    "                continue\n",
    "            sheet2_row_title = sheet2_row['Loan Title']\n",
    "            title_ratio = fuzz.token_sort_ratio(sheet1_row_title, sheet2_row_title)\n",
    "            title_ratios.append(title_ratio)\n",
    "            if title_ratio > 75:\n",
    "                possible_matches.append((title_ratio, sheet1_row, sheet2_row))\n",
    "    return possible_matches\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illrecpur_to_borrowing_requests_possible_matches = make_matches(reduced_illrecpur, borrowing_requests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illrecpur_to_borrowing_requests_possible_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writable_ill_brpm = []\n",
    "for a, b, c in illrecpur_to_borrowing_requests_possible_matches:\n",
    "    c['requested by']\n",
    "    writable_ill_brpm.extend([c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dict_to_csv('Feb13MikeSource/illrecpur_to_borrowing_requests_matches2.csv', writable_ill_brpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
